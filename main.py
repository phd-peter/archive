from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, HttpUrl, Field
from typing import List, Dict
import requests
import base64
from io import BytesIO
from PIL import Image
import os
import json
from dotenv import load_dotenv
from openai import OpenAI

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ë° OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

app = FastAPI(title="Image OCR Service")

class ImageRequest(BaseModel):
    web_content_link: HttpUrl = Field(
        ...,
        description="Google Driveì˜ webContentLink í˜•íƒœë¡œ, anyone-with-link ìƒíƒœì—¬ì•¼ í•©ë‹ˆë‹¤."
    )
    labels: List[str] = Field(
        ...,
        min_items=1,
        description="ìµœì†Œ 1ê°œ ì´ìƒì˜ ë¼ë²¨ì„ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ë¡œ ì „ë‹¬í•©ë‹ˆë‹¤."
    )

class OCRResult(BaseModel):
    label: str
    text: str

class ImageResponse(BaseModel):
    results: List[OCRResult]

def create_dynamic_tool(labels: List[str]) -> Dict:
    """ì‚¬ìš©ìê°€ ì œê³µí•œ labelsë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë™ì ìœ¼ë¡œ tool calling êµ¬ì¡° ìƒì„±"""
    properties = {}
    
    for label in labels:
        properties[label] = {
            "type": "string",
            "description": f"Extract {label} information from the image"
        }
    
    tool = [{
        "type": "function",
        "name": "extract_image_data",
        "description": "Extract specified data fields from the image",
        "parameters": {
            "type": "object",
            "properties": properties,
            "required": labels,
            "additionalProperties": False
        }
    }]
    
    return tool

def call_openai_vision(image_b64: str, labels: List[str]) -> Dict:
    """OpenAI Vision APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì´ë¯¸ì§€ì—ì„œ ë°ì´í„° ì¶”ì¶œ"""
    
    # ë™ì ìœ¼ë¡œ tool ìƒì„±
    tool = create_dynamic_tool(labels)
    print(f"ğŸ”§ Generated Tool: {json.dumps(tool, indent=2, ensure_ascii=False)}")
    
    # ì´ë¯¸ì§€ ì…ë ¥ êµ¬ì„±
    messages = [
        {
            "role": "system",
            "content": "You are a helpful assistant that extracts structured data from images. Please analyze the image carefully and extract the requested information."
        },
        {
            "role": "user",
            "content": [
                {
                    "type": "input_image",
                    "image_url": f"data:image/jpeg;base64,{image_b64}"
                }
            ]
        }
    ]
    
    print(f"ğŸ“¨ Messages structure: {json.dumps([{'role': msg['role'], 'content_type': type(msg['content']).__name__, 'content_keys': list(msg['content'][0].keys()) if isinstance(msg['content'], list) else 'string'} for msg in messages], indent=2, ensure_ascii=False)}")
    
    try:
        print("ğŸš€ Calling OpenAI API...")
        print(f"ğŸ“‹ Labels: {labels}")
        print(f"ğŸ–¼ï¸ Image base64 length: {len(image_b64)} characters")
        
        response = client.responses.create(
            model="gpt-4o",
            input=messages,
            tools=tool
        )
        
        print(f"âœ… OpenAI API Response received")
        print(f"ğŸ“„ Response type: {type(response)}")
        print(f"ğŸ“„ Response attributes: {dir(response)}")
        
        # Tool call ê²°ê³¼ íŒŒì‹±
        print(f"ğŸ” Trying to parse: response.output[0].arguments")
        extracted_data = json.loads(response.output[0].arguments)
        print(f"âœ… Successfully extracted data: {extracted_data}")
        return extracted_data
        
    except AttributeError as e:
        error_msg = f"OpenAI API ì‘ë‹µ êµ¬ì¡° ì˜¤ë¥˜: {str(e)} | Available attributes: {dir(response) if 'response' in locals() else 'No response object'}"
        print(f"âŒ AttributeError: {error_msg}")
        raise HTTPException(
            status_code=500,
            detail=error_msg
        )
    except json.JSONDecodeError as e:
        error_msg = f"JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)} | Raw response: {response if 'response' in locals() else 'No response'}"
        print(f"âŒ JSONDecodeError: {error_msg}")
        raise HTTPException(
            status_code=500,
            detail=error_msg
        )
    except Exception as e:
        error_msg = f"OpenAI Vision API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)} | Error type: {type(e).__name__}"
        print(f"âŒ Exception: {error_msg}")
        raise HTTPException(
            status_code=500,
            detail=error_msg
        )

@app.post("/process", response_model=ImageResponse)
def process_image(req: ImageRequest):
    # 1) ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
    try:
        resp = requests.get(req.web_content_link)
        resp.raise_for_status()
    except requests.RequestException as e:
        raise HTTPException(
            status_code=400,
            detail=f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}"
        )
    
    image_bytes = resp.content

    # 2) Base64 ë³€í™˜
    image_b64 = base64.b64encode(image_bytes).decode("utf-8")

    # 3) OpenAI Vision APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ì¶”ì¶œ
    try:
        extracted_data = call_openai_vision(image_b64, req.labels)
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨: {str(e)}"
        )

    # 4) ê²°ê³¼ë¥¼ OCRResult í˜•íƒœë¡œ ë³€í™˜
    results: List[OCRResult] = []
    for label in req.labels:
        text_value = extracted_data.get(label, "ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        # ìˆ«ìì¸ ê²½ìš° ë¬¸ìì—´ë¡œ ë³€í™˜
        if isinstance(text_value, (int, float)):
            text_value = str(text_value)
        results.append(OCRResult(label=label, text=text_value))

    return ImageResponse(results=results)

@app.get("/")
async def root():
    """Hello World ì—”ë“œí¬ì¸íŠ¸"""
    return {"message": "Hello World"}

@app.get("/health")
async def health_check():
    """ì„œë²„ ìƒíƒœ í™•ì¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {"status": "healthy"}

if __name__ == "__main__":
    import uvicorn
    port = int(os.environ.get("PORT", 8000))
    uvicorn.run(app, host="0.0.0.0", port=port)